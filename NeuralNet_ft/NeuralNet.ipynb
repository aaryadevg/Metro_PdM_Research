{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import lightning.pytorch as pl\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from typing import Any\n",
    "from lightning.pytorch.utilities.types import STEP_OUTPUT, OptimizerLRScheduler\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "DATA_PATH = pathlib.Path(\"../Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather(DATA_PATH / \"Classification.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"timestamp\", \"Target\"]) # this is purely a classification no time steps are needed\n",
    "y = df[\"Target\"]\n",
    "\n",
    "# nm_undersampler = NearMiss(version=3, n_neighbors_ver3=3, n_jobs=-1) # Warning takes very long to run\n",
    "# X, y = nm_undersampler.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = torch.from_numpy(X_train)\n",
    "y_train_t = torch.from_numpy(y_train.to_numpy())\n",
    "X_test_t = torch.from_numpy(X_test)\n",
    "y_test_t = torch.from_numpy(y_test.to_numpy())\n",
    "\n",
    "# Create the dataset object\n",
    "train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "test_ds = TensorDataset(X_test_t, y_test_t)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32)\n",
    "test_loader = DataLoader(test_ds, batch_size=32)\n",
    "\n",
    "X_train_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_Classifier(pl.LightningModule):\n",
    "    def __init__(self, n_inputs) -> None:\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(16, 256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 3)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx) -> STEP_OUTPUT:\n",
    "        X, y = batch\n",
    "        y_pred = self(X)\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx) -> STEP_OUTPUT:\n",
    "        X, y = batch\n",
    "        y_pred = self(X)\n",
    "        y_lab = torch.argmax(F.softmax(y_pred, dim=1), dim=1)\n",
    "        \n",
    "        correct = (y_lab == y).sum()\n",
    "        acc = correct / X.shape[0]\n",
    "        \n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self) -> OptimizerLRScheduler:\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-3)\n",
    "        \n",
    "        scheduler = {\n",
    "            'scheduler': ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True),\n",
    "            'monitor': 'val_loss',\n",
    "        }\n",
    "        return [optimizer], [scheduler]\n",
    "        \n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 25.2 K\n",
      "-------------------------------------\n",
      "25.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "25.2 K    Total params\n",
      "0.101     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1187/1187 [00:07<00:00, 155.73it/s, v_num=27, val_loss=0.517, val_acc=0.761]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1187/1187 [00:07<00:00, 155.54it/s, v_num=27, val_loss=0.517, val_acc=0.761]\n"
     ]
    }
   ],
   "source": [
    "model = NN_Classifier(X_train_t.shape[1])\n",
    "es_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=10, strict=True)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", callbacks=[es_callback], max_epochs=100)\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77      6529\n",
      "           1       0.75      0.87      0.80      6444\n",
      "           2       0.74      0.57      0.64      3303\n",
      "\n",
      "    accuracy                           0.76     16276\n",
      "   macro avg       0.76      0.73      0.74     16276\n",
      "weighted avg       0.76      0.76      0.76     16276\n",
      "\n",
      "[[0.75509266 0.1828764  0.06203094]\n",
      " [0.09233395 0.86638734 0.04127871]\n",
      " [0.23705722 0.19709355 0.56584923]]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_t)\n",
    "    y_hat = torch.argmax(F.softmax(y_pred, dim=1), dim=1).detach().cpu().numpy()\n",
    "    y_true = y_test_t.numpy()\n",
    "\n",
    "    print(classification_report(y_true, y_hat))\n",
    "    print(confusion_matrix(y_true, y_hat, normalize=\"true\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = pathlib.Path(\"../Model\")\n",
    "torch.save(model.state_dict(), MODEL_PATH / \"wights_raw.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.save(model.to_torchscript(method='trace', \n",
    "                                    example_inputs=X_train_t[0].view(1, -1)), \n",
    "               f = MODEL_PATH / \"script_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.7855956e-01,  1.1177493e+00,  6.5752178e-01, ...,\n",
       "        -5.2769203e-04, -3.8615271e-02, -4.2659864e-01],\n",
       "       [-3.7855956e-01,  1.1177493e+00,  6.5752178e-01, ...,\n",
       "        -5.2769203e-04, -3.8615271e-02, -4.2659864e-01],\n",
       "       [-3.7790960e-01,  1.1177493e+00,  6.5752178e-01, ...,\n",
       "        -5.2769203e-04, -3.8615271e-02, -4.2659864e-01],\n",
       "       ...,\n",
       "       [-3.7790960e-01, -7.6653486e-01,  1.4803013e-01, ...,\n",
       "        -5.2769203e-04, -3.8615271e-02, -4.2659864e-01],\n",
       "       [-3.7790960e-01, -7.6653486e-01,  1.4803013e-01, ...,\n",
       "        -5.2769203e-04, -3.8615271e-02, -4.2659864e-01],\n",
       "       [-3.7725961e-01, -7.6653486e-01,  1.4803013e-01, ...,\n",
       "        -5.2769203e-04, -3.8615271e-02, -4.2659864e-01]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=[\"timestamp\", \"Target\"]) # this is purely a classification no time steps are needed\n",
    "y = df[\"Target\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_s = scaler.fit_transform(X)\n",
    "\n",
    "X_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\Model\\\\scaler.pkl']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(scaler, MODEL_PATH / \"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.2432, -0.3997, -4.1261]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "MODEL_PATH = pathlib.Path(\"../Model\")\n",
    "m2 = NN_Classifier(n_inputs=16)\n",
    "m2.load_state_dict(torch.load(MODEL_PATH / \"wights_raw.pickle\"))\n",
    "\n",
    "scaler = joblib.load(MODEL_PATH / 'scaler.pkl')\n",
    "\n",
    "df = pd.read_feather(DATA_PATH / \"Classification.feather\")\n",
    "\n",
    "F = df.drop(columns=[\"timestamp\", \"Target\"]) # this is purely a classification no time steps are needed\n",
    "t = df[\"Target\"]\n",
    "\n",
    "X_new = F.iloc[0].to_numpy(dtype=float)\n",
    "s = scaler.transform(X_new.reshape(-1, 16))\n",
    "s = torch.tensor(s, dtype=torch.float32)\n",
    "\n",
    "m2(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
