{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from lightning.pytorch.utilities.types import STEP_OUTPUT, OptimizerLRScheduler\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((774, 84, 16), (774,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.load(\"X.npy\")\n",
    "y = np.load(\"y.npy\")\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((619, 84, 16), (155, 84, 16), (619,), (155,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2], dtype=int64), array([207, 205, 207], dtype=int64))\n",
      "(array([0, 1, 2], dtype=int64), array([51, 53, 51], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train, return_counts=True))\n",
    "print(np.unique(y_test, return_counts=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = torch.from_numpy(X_train)\n",
    "y_train_t = torch.from_numpy(y_train)\n",
    "X_test_t = torch.from_numpy(X_test)\n",
    "y_test_t = torch.from_numpy(y_test)\n",
    "\n",
    "# Create the dataset object\n",
    "train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "test_ds = TensorDataset(X_test_t, y_test_t)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, num_workers=1, persistent_workers=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, num_workers=1, persistent_workers=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Classifer(pl.LightningModule):\n",
    "    def __init__(self, n_features = 16, n_classes = 3, n_hidden = 64, n_layers = 3, dropout = 0.6) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size  = n_features,\n",
    "            hidden_size = n_hidden,\n",
    "            num_layers  = n_layers,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(n_hidden, n_classes)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        _ , (out, _) = self.lstm(x)\n",
    "        return self.classifier(out[-1])\n",
    "    \n",
    "    def training_step(self, batch, batch_idx) -> STEP_OUTPUT:\n",
    "        X, y = batch\n",
    "        y_pred = self(X)\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        y_lab = torch.argmax(F.softmax(y_pred, dim=1), dim=1)\n",
    "        acc = accuracy(y_lab, y, task=\"multiclass\", num_classes=3)\n",
    "        \n",
    "        self.log(\"acc\", acc, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        self.log(\"loss\", loss, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx) -> STEP_OUTPUT:\n",
    "        X, y = batch\n",
    "        y_pred = self(X)\n",
    "        y_lab = torch.argmax(F.softmax(y_pred, dim=1), dim=1)\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        acc = accuracy(y_lab,y, task=\"multiclass\", num_classes=3)\n",
    "        \n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self) -> OptimizerLRScheduler:\n",
    "        return torch.optim.Adam(self.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\loops\\utilities.py:72: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type   | Params\n",
      "--------------------------------------\n",
      "0 | lstm       | LSTM   | 154 K \n",
      "1 | classifier | Linear | 195   \n",
      "--------------------------------------\n",
      "154 K     Trainable params\n",
      "0         Non-trainable params\n",
      "154 K     Total params\n",
      "0.617     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:293: The number of training batches (20) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 20/20 [00:00<00:00, 110.90it/s, v_num=53, val_loss=0.803, val_acc=0.761, acc=0.863, loss=0.351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 20/20 [00:00<00:00, 102.39it/s, v_num=53, val_loss=0.803, val_acc=0.761, acc=0.863, loss=0.351]\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_Classifer(n_layers= 5, n_hidden=64, dropout=0.2)\n",
    "es_callback = EarlyStopping(monitor=\"val_loss\", patience=15, strict=False, mode=\"min\")\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"Lstm_v2\")\n",
    "\n",
    "pl.seed_everything(42)\n",
    "\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", \n",
    "                     #callbacks=[es_callback], \n",
    "                     min_epochs=50,\n",
    "                     logger=logger)\n",
    "\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155, 155)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "all_pred = []\n",
    "all_true = []\n",
    "\n",
    "for batch in test_loader:\n",
    "    cX, cy = batch\n",
    "    \n",
    "    pred = torch.argmax(F.softmax(model(cX), dim=1), dim=1).detach().cpu().tolist()\n",
    "    true = cy.detach().cpu().tolist()\n",
    "    \n",
    "    all_pred.extend(pred)\n",
    "    all_true.extend(true)\n",
    "\n",
    "\n",
    "len(all_true) , len(all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78        51\n",
      "           1       0.65      0.85      0.74        53\n",
      "           2       0.94      0.65      0.77        51\n",
      "\n",
      "    accuracy                           0.76       155\n",
      "   macro avg       0.79      0.76      0.76       155\n",
      "weighted avg       0.79      0.76      0.76       155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(all_true, all_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7601430509310642"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(all_true, all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
